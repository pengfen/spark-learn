1. 数据处理流程
该项目是一个纯粹的数据分析项目，其整体流程基本上就是依据数据的处理流程进行，依此有以下几个大的步骤：
1)数据采集
首先，通过页面嵌入JS代码的方式获取用户访问行为，并发送到web服务的后台记录日志
然后，将各服务器上生成的点击流日志通过实时或批量的方式汇聚到HDFS文件系统中

当然，一个综合分析系统，数据源可能不仅包含点击流数据，还有数据库中的业务数据（如用户信息、商品信息、订单信息等）及对分析有益的外部数据。

2)数据预处理
通过mapreduce程序对采集到的点击流数据进行预处理，比如清洗，格式整理，滤除脏数据等

3)数据入库
将预处理之后的数据导入到HIVE仓库中相应的库和表中

4)数据分析
项目的核心内容，即根据需求开发ETL分析语句，得出各种统计结果

5)数据展现
将分析所得数据进行可视化






2. 项目结构
由于本项目是一个纯粹数据分析项目，其整体结构亦跟分析流程匹配，并没有特别复杂的结构，如下图：

其中，需要强调的是：
系统的数据分析不是一次性的，而是按照一定的时间频率反复计算，因而整个处理链条中的各个环节需要按照一定的先后依赖关系紧密衔接，
即涉及到大量任务单元的管理调度，所以，项目中需要添加一个任务调度模块

2.3 数据展现
数据展现的目的是将分析所得的数据进行可视化，以便运营决策人员能更方便地获取数据，更快更简单地理解数据