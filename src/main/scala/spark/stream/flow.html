spark streaming 开发

1. 添加依赖
<spark.version>2.2.0</spark.version>

<!--  Spark Streaming 依赖 -->
<dependency>
    <groupId>org.apache.spark</groupId>
    <artifactId>spark-streaming_2.11</artifactId>
    <version>${spark.version}</version>
</dependency>

2. 编写 NetworkWordCount (spark streaming处理socket数据)

添加依赖
<dependency>
    <groupId>com.fasterxml.jackson.module</groupId>
    <artifactId>jackson-module-scala_2.11</artifactId>
    <version>2.6.5</version>
</dependency>
<dependency>
    <groupId>net.jpountz.lz4</groupId>
    <artifactId>lz4</artifactId>
    <version>1.3.0</version>
</dependency>

3. 编写 FileWordCount (spark streaming处理HDFS文件数据)

4. 编写 StatefulWordCount (使用Spark Streaming完成有状态统计)

5. 处理 错误: 找不到或无法加载主类 com.spark_stream.FileWordCount
target中class文件被删了，需要重新编译
ricky@ricky:~/IdeaProjects/spark-learn$ mvn compile

6. 右边显示树形目录结构
File ---> Project Structure ---> Module ---> Import Module ---> import module from external module
---> Maven ---> 下一步 --> finished

7. 编写 SqlNetworkWordCount (计算到目前为止累积出现的单词个数写入到MySQL)

8. 创建数据表
create table wordcount(
word varchar(50) default null,
wordcount int(10) default null
);

create database spark_learn
use spark_learn

添加依赖
<dependency>
    <groupId>mysql</groupId>
    <artifactId>mysql-connector-java</artifactId>
    <version>5.1.38</version>
</dependency>

9. 编写 TransformApp (黑名单过滤)

10. 编写 SqlNetworkWordCount (spark streaming 整合 spark sql 实战)
添加依赖
<!--  Spark SQL 依赖 -->
<dependency>
    <groupId>org.apache.spark</groupId>
    <artifactId>spark-sql_2.11</artifactId>
    <version>${spark.version}</version>
</dependency>