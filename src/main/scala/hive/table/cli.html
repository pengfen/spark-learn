Hive函数

1. 内置运算符
内容较多，见《Hive官方文档》

2. 内置函数
内容较多，见《Hive官方文档》



3. Hive自定义函数和Transform
当Hive提供的内置函数无法满足你的业务处理需要时，此时就可以考虑使用用户自定义函数（UDF：user-defined function）。

自定义函数类别
UDF  作用于单个数据行，产生一个数据行作为输出。（数学函数，字符串函数）
UDAF（用户定义聚集函数）：接收多个输入数据行，并产生一个输出数据行。（count，max）

UDF开发实例
1、先开发一个java类，继承UDF，并重载evaluate方法
package cn.itcast.bigdata.udf
import org.apache.hadoop.hive.ql.exec.UDF;
import org.apache.hadoop.io.Text;

public final class Lower extends UDF{
public Text evaluate(final Text s){
if(s==null){return null;}
return new Text(s.toString().toLowerCase());
}
}

2、打成jar包上传到服务器
3、将jar包添加到hive的classpath
hive>add JAR /home/hadoop/udf.jar;
4、创建临时函数与开发好的java class关联
Hive>create temporary function toprovince as 'cn.itcast.bigdata.udf.ToProvince';

5、即可在hql中使用自定义的函数strip 
Select strip(name),age from t_test;

4. Transform实现
Hive的 TRANSFORM 关键字提供了在SQL中调用自写脚本的功能
适合实现Hive中没有的功能又不想写UDF的情况

使用示例1：下面这句sql就是借用了weekday_mapper.py对数据进行了处理.
CREATE TABLE u_data_new (
movieid INT,
rating INT,
weekday INT,
userid INT)
ROW FORMAT DELIMITED
FIELDS TERMINATED BY '\t';

add FILE weekday_mapper.py;

INSERT OVERWRITE TABLE u_data_new
SELECT
TRANSFORM (movieid, rating, unixtime,userid)
USING 'python weekday_mapper.py'
AS (movieid, rating, weekday,userid)
FROM u_data;

其中weekday_mapper.py内容如下
#!/bin/python
import sys
import datetime

for line in sys.stdin:
line = line.strip()
movieid, rating, unixtime,userid = line.split('\t')
weekday = datetime.datetime.fromtimestamp(float(unixtime)).isoweekday()
print '\t'.join([movieid, rating, str(weekday),userid])

使用示例2：下面的例子则是使用了shell的cat命令来处理数据
FROM invites a INSERT OVERWRITE TABLE events SELECT TRANSFORM(a.foo, a.bar) AS (oof, rab) USING '/bin/cat' WHERE a.ds > '2008-08-09';