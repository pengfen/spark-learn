Spark Streaming 整合 kafka 方式之一 之 Receiver整合
1. 启动zk
cd $ZK_HOME
bin/zkServer.sh start

2. 启动kafka
cd $KAFKA_HOME
bin/kafka-server-start.sh

2. 启动kafka
bin/kafka-server-start.sh -daemon /home/ricky/app/kafka_2.11-0.9.0.0/config/server.properties

3. 创建topic
bin/kafka-topics.sh --create --zookeeper localhost:2181 --replication-factor 1 --partitions 1 --topic kafka_streaming_topic

bin/kafka-topics.sh --list --zookeeper localhost:2181 # 查看topic

4. 通过控制台测试本topic是否能够正常的生产和消费
bin/kafka-console-producer.sh --broker-list localhost:9092 --topic kafka_streaming_topic

bin/kafka-console-consumer.sh --zookeeper localhost:2181 --topic kafka_streaming_topic

5. 编写代码 KafkaRecevierWordCount

6. 编辑参数
ricky:2181 test kafka_streaming_topic 1

7. 运行代码

8. 生产者生产
ricky@ricky:~/app/kafka_2.11-0.9.0.0/bin$ ./kafka-console-producer.sh --broker-list localhost:9092 --topic kafka_streaming_topic
Picked up _JAVA_OPTIONS: -Dawt.useSystemAAFontSettings=gasp
a a a a
b b b
c c
d

9. 查看控制台
(a,4)
(d,1)
(b,3)
(c,2)

Spark Streaming对接Kafka的方式二 Direct方式
1. 启动zk
bin/zkServer.sh start

2. 启动kafka
bin/kafka-server-start.sh

2. 启动kafka
bin/kafka-server-start.sh -daemon /home/ricky/app/kafka_2.11-0.9.0.0/config/server.properties

3. 创建topic
bin/kafka-topics.sh --create --zookeeper localhost:2181 --replication-factor 1 --partitions 1 --topic kafka_streaming_topic

bin/kafka-topics.sh --list --zookeeper localhost:2181 # 查看topic

4. 通过控制台测试本topic是否能够正常的生产和消费
bin/kafka-console-producer.sh --broker-list localhost:9092 --topic kafka_streaming_topic

bin/kafka-console-consumer.sh --zookeeper localhost:2181 --topic kafka_streaming_topic

5. 编写代码 KafkaDirectWordCount


6.输入
ricky@ricky:~/app/kafka_2.11-0.9.0.0/bin$ ./kafka-console-producer.sh --broker-list localhost:9092 --topic kafka_streaming_topic
Picked up _JAVA_OPTIONS: -Dawt.useSystemAAFontSettings=gasp
a a a a
b b b
c c
d

7.查看控制台
(a,4)
(d,1)
(b,3)
(c,2)